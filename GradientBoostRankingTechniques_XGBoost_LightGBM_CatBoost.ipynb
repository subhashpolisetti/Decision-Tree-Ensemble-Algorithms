{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAsDNXyz+snKM95METNzuV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subhashpolisetti/Decision-Tree-Ensemble-Algorithms/blob/main/GradientBoostRankingTechniques_XGBoost_LightGBM_CatBoost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ranking Models Comparison: XGBoost, LightGBM, and CatBoost\n",
        "\n",
        "This notebook demonstrates the implementation and comparison of three popular ranking models—**XGBoost**, **LightGBM**, and **CatBoost**—on a synthetic ranking dataset. The goal is to predict the relevance of items in a ranked list for a set of queries. Each of these models is widely used for ranking tasks in machine learning and provides powerful tools for learning to rank items based on their relevance.\n",
        "\n",
        "## Key Concepts:\n",
        "\n",
        "1. **Ranking Models**: In ranking tasks, the model learns to assign a relevance score to items within a query. The objective is to rank the items in an order based on their predicted relevance, rather than classifying them into fixed categories or predicting continuous values.\n",
        "\n",
        "2. **XGBoost**: XGBoost (Extreme Gradient Boosting) is a highly efficient and scalable machine learning algorithm. For ranking tasks, it uses the **pairwise ranking** objective (`rank:pairwise`), which learns to compare pairs of items in terms of relevance.\n",
        "\n",
        "3. **LightGBM**: LightGBM (Light Gradient Boosting Machine) is a fast, distributed, high-performance implementation of gradient boosting. It is optimized for large datasets and has a ranking-specific objective called **LambdaRank**.\n",
        "\n",
        "4. **CatBoost**: CatBoost is a gradient boosting framework that is particularly efficient with categorical features. It offers a **ranking-specific objective** for learning to rank problems, called **`lambdarank`**.\n",
        "\n",
        "## Steps in the Notebook:\n",
        "\n",
        "1. **Synthetic Dataset**: We create a synthetic ranking dataset with 100 samples, 5 features, and relevance scores ranging from 1 to 5. The dataset is split into two groups of queries.\n",
        "\n",
        "2. **Train/Test Split**: The dataset is divided into training (80%) and testing (20%) subsets, ensuring that each group contains the relevant data.\n",
        "\n",
        "3. **Model Training**:\n",
        "    - **XGBoost**: The XGBoost model is trained using the `rank:pairwise` objective.\n",
        "    - **LightGBM**: The LightGBM model is trained using the `lambdarank` objective.\n",
        "    - **CatBoost**: The CatBoost model is trained using the `lambdarank` objective.\n",
        "\n",
        "4. **Prediction and Evaluation**: After training, each model predicts the relevance scores for the test data, and the predictions are displayed for comparison.\n",
        "\n",
        "5. **Comparison**: The predictions from **XGBoost**, **LightGBM**, and **CatBoost** are compared side by side to evaluate their performance on the ranking task.\n",
        "\n",
        "## Libraries Used:\n",
        "- **XGBoost**: For training the XGBoost ranking model.\n",
        "- **LightGBM**: For training the LightGBM ranking model.\n",
        "- **CatBoost**: For training the CatBoost ranking model.\n",
        "- **NumPy**: For generating and manipulating the synthetic dataset.\n",
        "\n",
        "## Results:\n",
        "- The predicted ranking scores from all three models are printed, allowing for an easy comparison of their performance.\n",
        "\n",
        "This notebook helps to understand how different ranking models work and compares their predictions on a synthetic ranking task. Feel free to experiment with hyperparameter tuning or use real-world ranking datasets to test these models' effectiveness.\n"
      ],
      "metadata": {
        "id": "CE7PlR58yZJA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CLnBlmSx_Co",
        "outputId": "eef194f9-d655-4598-e2b8-ee42310a3fa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Ranking Predictions: [-0.9623178   0.04632036 -1.1156845   0.6520399  -0.06923307  0.40256834\n",
            " -0.53648645  0.6583479  -0.5993957   0.10472348 -0.16147704 -0.3133536\n",
            " -0.08844604  0.04491812 -0.22709228  0.22807404  0.08727098 -0.4425296\n",
            " -0.30992997 -1.1322114 ]\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBRanker\n",
        "import numpy as np\n",
        "\n",
        "# Generate a synthetic ranking dataset\n",
        "X = np.random.rand(100, 5)  # 100 samples, each with 5 random features\n",
        "y = np.random.randint(1, 6, size=100)  # Random relevance scores (between 1 and 5)\n",
        "group = [50, 50]  # Two groups of 50 samples, each representing a query\n",
        "\n",
        "# Train/Test Split\n",
        "X_train, X_test = X[:80], X[80:]  # Use the first 80 samples for training and the rest for testing\n",
        "y_train, y_test = y[:80], y[80:]  # Split the relevance scores correspondingly\n",
        "group_train = [40, 40]  # Each group in the training set contains 40 items\n",
        "group_test = [10, 10]  # Each group in the test set contains 10 items\n",
        "\n",
        "# Initialize and train the XGBoost Ranker model\n",
        "xgb_ranker = XGBRanker(\n",
        "    objective=\"rank:pairwise\",  # Pairwise ranking objective, where the model learns to rank pairs of items\n",
        "    learning_rate=0.1,          # The learning rate that controls how much the model adjusts during each iteration\n",
        "    max_depth=3,                # Maximum depth of each decision tree to prevent overfitting\n",
        "    n_estimators=100            # The number of boosting rounds (trees) to train\n",
        ")\n",
        "\n",
        "# Fit the model on the training data with the specified group information\n",
        "xgb_ranker.fit(X_train, y_train, group=group_train)\n",
        "\n",
        "# Predict the relevance scores for the test data\n",
        "y_pred = xgb_ranker.predict(X_test)\n",
        "\n",
        "# Print the predicted ranking scores for the test data\n",
        "print(\"XGBoost Ranking Predictions:\", y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "# Dataset and groups for LightGBM\n",
        "lgb_train = lgb.Dataset(X_train, y_train, group=group_train)  # Create LightGBM dataset for training\n",
        "lgb_test = lgb.Dataset(X_test, y_test, group=group_test, reference=lgb_train)  # Create LightGBM dataset for testing\n",
        "\n",
        "# Set the parameters for the LightGBM Ranker\n",
        "params = {\n",
        "    \"objective\": \"lambdarank\",  # The objective function for ranking (LambdaRank is used for learning to rank)\n",
        "    \"metric\": \"ndcg\",           # The evaluation metric (Normalized Discounted Cumulative Gain)\n",
        "    \"learning_rate\": 0.1,       # The learning rate, which controls how much the model is updated in each iteration\n",
        "    \"max_depth\": 3,             # Maximum depth of the trees to prevent overfitting\n",
        "    \"num_leaves\": 31,           # Number of leaves in each tree, affecting model complexity\n",
        "}\n",
        "\n",
        "# Train the LightGBM ranking model using the training dataset and parameters\n",
        "lgb_ranker = lgb.train(\n",
        "    params,            # Parameters defined above\n",
        "    lgb_train,         # Training dataset\n",
        "    valid_sets=[lgb_test]  # Use lgb_test as the validation set to monitor performance\n",
        ")\n",
        "\n",
        "# Predict ranking scores for the test dataset\n",
        "y_pred = lgb_ranker.predict(X_test)\n",
        "\n",
        "# Print the predicted ranking scores for the test set\n",
        "print(\"LightGBM Ranking Predictions:\", y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL2Xn-E_yiX_",
        "outputId": "85a688ce-405c-46bc-9eed-b5946d67ab30"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016488 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 140\n",
            "[LightGBM] [Info] Number of data points in the train set: 80, number of used features: 5\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "LightGBM Ranking Predictions: [-0.72329493  0.78000156  0.05968753  0.64799642 -0.58830022 -0.45155588\n",
            " -0.77904294  1.93025642 -0.69964296 -2.3539077  -0.28196066 -2.52643691\n",
            "  1.0309714  -2.38831163 -0.84669579 -0.5433052  -1.95342094 -0.77104739\n",
            " -2.38424839 -2.47131722]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5j3ch-iywYg",
        "outputId": "7f2aceb5-4b9f-4644-9777-a88f38b9c0ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostRanker, Pool\n",
        "\n",
        "# Pool for ranking: Prepare the data for CatBoost\n",
        "# The group_id specifies which items belong to the same query (group of items to rank)\n",
        "train_pool = Pool(X_train, y_train, group_id=[0] * 40 + [1] * 40)  # Training pool with 2 groups\n",
        "test_pool = Pool(X_test, y_test, group_id=[0] * 10 + [1] * 10)  # Test pool with 2 groups\n",
        "\n",
        "# Initialize and train the CatBoost Ranker model\n",
        "catboost_ranker = CatBoostRanker(\n",
        "    iterations=100,           # The number of boosting iterations (trees)\n",
        "    learning_rate=0.1,        # The learning rate (controls model adjustments at each iteration)\n",
        "    depth=3,                  # The maximum depth of each tree\n",
        "    verbose=10                # Print progress every 10 iterations\n",
        ")\n",
        "\n",
        "# Fit the model on the training data\n",
        "catboost_ranker.fit(train_pool)\n",
        "\n",
        "# Predict the ranking for the test data\n",
        "y_pred = catboost_ranker.predict(test_pool)\n",
        "\n",
        "# Print the predicted ranking scores for the test data\n",
        "print(\"CatBoost Ranking Predictions:\", y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndqIBb5uy9ap",
        "outputId": "c83ddaaa-fc73-44f2-b94b-eb73c9e8df57"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\ttotal: 47.7ms\tremaining: 4.72s\n",
            "10:\ttotal: 56.1ms\tremaining: 454ms\n",
            "20:\ttotal: 64.6ms\tremaining: 243ms\n",
            "30:\ttotal: 70.3ms\tremaining: 157ms\n",
            "40:\ttotal: 81.2ms\tremaining: 117ms\n",
            "50:\ttotal: 93.7ms\tremaining: 90ms\n",
            "60:\ttotal: 107ms\tremaining: 68.5ms\n",
            "70:\ttotal: 119ms\tremaining: 48.5ms\n",
            "80:\ttotal: 159ms\tremaining: 37.2ms\n",
            "90:\ttotal: 169ms\tremaining: 16.7ms\n",
            "99:\ttotal: 181ms\tremaining: 0us\n",
            "CatBoost Ranking Predictions: [-1.39999172  1.4968492  -1.73894059  1.42851333  0.23416513  0.78178116\n",
            " -0.14234553  1.38200394 -0.9499378  -0.47298719  2.32974744 -1.05942711\n",
            "  0.59158084 -0.13426086 -1.23678856  0.37088161 -0.63732242  0.08784243\n",
            " -0.67714497 -1.8269111 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store predictions from all models in a dictionary\n",
        "predictions = {}\n",
        "\n",
        "# XGBoost: Train the model and make predictions\n",
        "xgb_ranker.fit(X_train, y_train, group=group_train)  # Fit XGBoost model on the training data with group info\n",
        "predictions['XGBoost'] = xgb_ranker.predict(X_test)  # Store the predictions for the test data\n",
        "\n",
        "# LightGBM: Train the model and make predictions\n",
        "lgb_ranker = lgb.train(params, lgb_train)  # Train LightGBM model with the defined parameters and training data\n",
        "predictions['LightGBM'] = lgb_ranker.predict(X_test)  # Store the predictions for the test data\n",
        "\n",
        "# CatBoost: Train the model and make predictions\n",
        "catboost_ranker.fit(train_pool)  # Train the CatBoost model on the training pool\n",
        "predictions['CatBoost'] = catboost_ranker.predict(test_pool)  # Store the predictions for the test pool\n",
        "\n",
        "# Print the predictions for all models\n",
        "for model, preds in predictions.items():\n",
        "    print(f\"{model} Predictions:\", preds)  # Print the predictions from each model (XGBoost, LightGBM, CatBoost)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlT7EJkNzD7z",
        "outputId": "1695d1d2-06ec-4cf6-8e6b-e840c6ec4530"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 140\n",
            "[LightGBM] [Info] Number of data points in the train set: 80, number of used features: 5\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "0:\ttotal: 506us\tremaining: 50.1ms\n",
            "10:\ttotal: 8.19ms\tremaining: 66.2ms\n",
            "20:\ttotal: 27.7ms\tremaining: 104ms\n",
            "30:\ttotal: 36.1ms\tremaining: 80.4ms\n",
            "40:\ttotal: 41.3ms\tremaining: 59.4ms\n",
            "50:\ttotal: 47ms\tremaining: 45.2ms\n",
            "60:\ttotal: 52ms\tremaining: 33.2ms\n",
            "70:\ttotal: 57.4ms\tremaining: 23.4ms\n",
            "80:\ttotal: 69.7ms\tremaining: 16.3ms\n",
            "90:\ttotal: 86.4ms\tremaining: 8.55ms\n",
            "99:\ttotal: 91.9ms\tremaining: 0us\n",
            "XGBoost Predictions: [-0.9623178   0.04632036 -1.1156845   0.6520399  -0.06923307  0.40256834\n",
            " -0.53648645  0.6583479  -0.5993957   0.10472348 -0.16147704 -0.3133536\n",
            " -0.08844604  0.04491812 -0.22709228  0.22807404  0.08727098 -0.4425296\n",
            " -0.30992997 -1.1322114 ]\n",
            "LightGBM Predictions: [-0.72329493  0.78000156  0.05968753  0.64799642 -0.58830022 -0.45155588\n",
            " -0.77904294  1.93025642 -0.69964296 -2.3539077  -0.28196066 -2.52643691\n",
            "  1.0309714  -2.38831163 -0.84669579 -0.5433052  -1.95342094 -0.77104739\n",
            " -2.38424839 -2.47131722]\n",
            "CatBoost Predictions: [-1.39999172  1.4968492  -1.73894059  1.42851333  0.23416513  0.78178116\n",
            " -0.14234553  1.38200394 -0.9499378  -0.47298719  2.32974744 -1.05942711\n",
            "  0.59158084 -0.13426086 -1.23678856  0.37088161 -0.63732242  0.08784243\n",
            " -0.67714497 -1.8269111 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l7-jysC4zK1c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}